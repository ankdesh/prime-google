# -*- coding: utf-8 -*-
"""Copy of [PRIME, ICLR 2022] Colab Parsing Dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mIUepWQnhYY4B1oFM3SmwricB8cW8a6O

Copyright 2022 Google LLC.

Licensed under the Apache License, Version 2.0 (the "License");
"""

#@title License
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""#  Instructions to use PRIME dataset parser

This colab provides the details to parse the
[PRIME](https://arxiv.org/abs/2110.11346) dataset available on Google Cloud Storage: [gs://gresearch/prime](https://console.cloud.google.com/storage/browser/gresearch/prime)

You may download the dataset either by using the Google Cloud Storage web interface or using gsutil:

```
gsutil cp -r gs://gresearch/prime /tmp/prime/
```

The PRIME dataset contains **10** microarchitectural parameters, including number of compute units, on-chip memory size, and number of SIMD units, along with the Runtime (millisecond) and Chip Area Usage (mm$^2$) for all the nine applications that we evaluated in our paper.

The data in this dataset are collected using an industry-grade cycle-accurate simulator. 

This dataset contains both infeasible and feasible data points as described in
[PRIME](https://arxiv.org/abs/2110.11346). The descriptors of the collected
data are presented in the table below (Table 1).

|                  | # of Infeasible | # of Feasible | Max Runtime (ms) | Min Runtime (ms) | Average Runtime (ms) |
|------------------|-----------------|---------------|------------------|------------------|----------------------|
| **MobileNetEdgeTPU** |          384355 |        115711 |         16352.26 |           252.22 |               529.13 |
| **MobilenetV2**      |          744718 |        255414 |          7398.13 |           191.35 |               375.05 |
| **MobilenetV3**      |          797460 |        202672 |          7001.46 |           405.19 |               993.75 |
| **M4**               |          791984 |        208148 |         35881.35 |           335.59 |               794.33 |
| **M5**               |          698618 |        301514 |         35363.55 |           202.55 |               440.52 |
| **M6**               |          756468 |        243664 |          4236.90 |           127.79 |               301.74 |
| **UNet**             |          449578 |         51128 |        124987.51 |           610.96 |              3681.75 |
| **T-RNN Dec**        |          405607 |         94459 |          4447.74 |           128.05 |               662.44 |
| **T-RNN Enc**        |          410933 |         88880 |          5112.82 |           127.97 |               731.20 |
"""

#@title Listing the data for the studied application

#@title Importing the necessary libraries
import tensorflow as tf
import numpy as np
import os

#@title APIs for parsing PRIME datasets
def parse_prime_tfrecords(proto):
  prime_feature_description = {  
    'param_1': tf.io.FixedLenFeature([], tf.float32),
    'param_2': tf.io.FixedLenFeature([], tf.float32),
    'param_3': tf.io.FixedLenFeature([], tf.float32),
    'param_4': tf.io.FixedLenFeature([], tf.float32),
    'param_5': tf.io.FixedLenFeature([], tf.float32),
    'param_6': tf.io.FixedLenFeature([], tf.float32),
    'param_7': tf.io.FixedLenFeature([], tf.float32),
    'param_8': tf.io.FixedLenFeature([], tf.float32),
    'param_9': tf.io.FixedLenFeature([], tf.float32),
    'param_10': tf.io.FixedLenFeature([], tf.float32),
    'runtime': tf.io.FixedLenFeature([], tf.float32),
    'area': tf.io.FixedLenFeature([], tf.float32),
    'infeasible':tf.io.FixedLenFeature([], tf.int64),
  }
  return tf.io.parse_single_example(proto, prime_feature_description)

#@title Parsing the dataset for the studied application
#for model_name in ["MobilenetV4", "MobilenetV3", "m4", "m5", "m6", "t_rnn_dec", "t_rnn_enc", "u-net"]:
print ("Models to evaluate" , os.getenv("MODELS").split(','))
for model_name in os.getenv("MODELS").split(','):
  for data_type in ["feasible", "infeasible"]:
    print (f"------Parsing {model_name}:{data_type}")
    #model_name = 'MobilenetEdgeTPU' #@param ["MobilenetEdgeTPU", "MobilenetV2", "MobilenetV3", "m4", "m5", "m6", "t_rnn_dec", "t_rnn_enc", "u-net"]
    filename = f"dataset/{model_name}/{model_name}_{data_type}.tfrecord"
    filenames = tf.io.gfile.glob(filename)
    raw_dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=64)
    parsed_dataset = raw_dataset.map(parse_prime_tfrecords)
    
    #@title Reproducing the data in the Table 1
    number_of_infeasibles = 0
    number_of_feasibles = 0
    
    import pandas as pd
    df = pd.DataFrame(columns=['param_1','param_2','param_3','param_4','param_5','param_6','param_7','param_8','param_9','param_10','runtime','area','infeasible'])
    i=0
    for p in parsed_dataset:
        df.loc[i, ['param_1']] = p['param_1']
        df.loc[i, ['param_2']] = p['param_2']
        df.loc[i, ['param_3']] = p['param_3']
        df.loc[i, ['param_4']] = p['param_4']
        df.loc[i, ['param_5']] = p['param_5']
        df.loc[i, ['param_6']] = p['param_6']
        df.loc[i, ['param_7']] = p['param_7']
        df.loc[i, ['param_8']] = p['param_8']
        df.loc[i, ['param_9']] = p['param_9']
        df.loc[i, ['param_10']] = p['param_10']
        df.loc[i, ['runtime']] = p['runtime']
        df.loc[i, ['area']] = p['area']
        df.loc[i, ['infeasible']] = p['infeasible']
        i = i + 1
        if (i%1000 == 0):
          print (f"Parsing {model_name}:{data_type}")
        # save in csv file, MobilenetEdgeTPU
    
    df.to_csv(f'dataset/{model_name}/{model_name}_{data_type}.csv')
